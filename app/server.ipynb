{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "server.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R214fKzfmHs3",
        "outputId": "40ecba7e-64d2-4bb3-fe93-8705e8cc358b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "import dill"
      ],
      "metadata": {
        "id": "Cir8CLxCnPQD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "0YgMLv40nsnT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
        "!tar -xvf /content/ngrok-stable-linux-amd64.tgz\n",
        "!./ngrok authtoken 2AQwxtl9lZmWOYwwGv3dptsb2GJ_21ZJCVJ59W9RjFNtN2CJ6\n",
        "!./ngrok http 80"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbVYrzwNjhNm",
        "outputId": "f80600bb-df6e-498f-ede7-b7f342185ef7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-22 14:48:05--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.161.241.46, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13770165 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.tgz.3’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  8.41MB/s    in 1.6s    \n",
            "\n",
            "2022-07-22 14:48:06 (8.41 MB/s) - ‘ngrok-stable-linux-amd64.tgz.3’ saved [13770165/13770165]\n",
            "\n",
            "ngrok\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            "/content/ngrok-stable-linux-amd64.tgz.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создаем сервис для обработки запросов к модели"
      ],
      "metadata": {
        "id": "BK8WeCBowqMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем обученные модели\n",
        "with open('gbc_pipeline.dill', 'rb') as in_strm:\n",
        "    model = dill.load(in_strm)\n",
        "  "
      ],
      "metadata": {
        "id": "07Xyr70sep2h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = pd.read_csv(\"X_test.csv\")\n",
        "y_test = pd.read_csv(\"y_test.csv\")"
      ],
      "metadata": {
        "id": "bjcJtoLaxLJH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустить сервис и не глушить его, пока работаем"
      ],
      "metadata": {
        "id": "Zke71BlkxTEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обработчики и запуск Flask\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when app is run\n",
        "\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def general():\n",
        "    return \"Welcome to prediction process\"\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = {\"success\": False}\n",
        "\n",
        "    # ensure an image was properly uploaded to our endpoint\n",
        "    comment = \"\"\n",
        "    request_json = request.get_json()\n",
        "    \n",
        "    if request_json[\"comment\"]:\n",
        "        comment = request_json['comment']\n",
        "    \n",
        "    print(comment)  \n",
        "    preds = model.predict_proba(pd.DataFrame({\"comment\": [comment]}))\n",
        "    data[\"predictions\"] = preds[:, 1][0]\n",
        "    data[\"comment\"] = comment\n",
        "        # indicate that the request was a success\n",
        "    data[\"success\"] = True\n",
        "    print('OK')\n",
        "\n",
        "        # return the data dictionary as a JSON response\n",
        "    return jsonify(data)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFZvw5zKxOiK",
        "outputId": "f672b781-ce5c-4555-f063-8da4db86d85f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://9061-35-196-60-181.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [22/Jul/2022 14:51:11] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2022 14:51:11] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [22/Jul/2022 14:51:20] \"\u001b[31m\u001b[1mGET /predict HTTP/1.1\u001b[0m\" 405 -\n",
            "127.0.0.1 - - [22/Jul/2022 14:51:38] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "[2022-07-22 15:06:29,627] ERROR in app: Exception on /predict [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-21-fbee72443b72>\", line 22, in predict\n",
            "    preds = model.predict_proba(pd.DataFrame({\"comment\": [comment]}))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 535, in predict_proba\n",
            "    Xt = transform.transform(Xt)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 1224, in transform\n",
            "    for name, trans, weight in self._iter()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1043, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 779, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
            "    res = transformer.transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 647, in transform\n",
            "    Xt = transform.transform(Xt)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 2101, in transform\n",
            "    X = super().transform(raw_documents)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 1379, in transform\n",
            "    _, X = self._count_vocab(raw_documents, fixed_vocab=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 1201, in _count_vocab\n",
            "    for feature in analyze(doc):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 113, in _analyze\n",
            "    doc = preprocessor(doc)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 71, in _preprocess\n",
            "    doc = doc.lower()\n",
            "AttributeError: 'list' object has no attribute 'lower'\n",
            "127.0.0.1 - - [22/Jul/2022 15:06:29] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Stylect is a dynamic startup that helps helps women discover and buy shoes. We’re a small team based in London that has previously worked at Google, Techstars, Pixelmator and Rocket Internet.We place a high premium on simplicity no matter what we’re working on (i.e. design, programming, marketing). We’re also a team that ships fast. We built version 1 of our app in a week, the next release (built in a month) was featured in the Apple Appstore Italy as a best new fashion app. Fast release cycles are challenging, but also very fun - which is why we love them.\\xa0As we’ve grown, the projects that we’re working on have grown both in scale and in technical complexity. \\xa0Stylect is looking for someone who can help us improve our backend which gathers product data; analyses/categorizes it; and shows it to thousands of users daily. Each step in the process has unique challenges that demands a strong technical background.', 'ustwo offers you the opportunity to be yourself, whilst delivering the best work on the planet for some of the biggest and most innovative brands. A culture thriving on collaboration underpins what is an amazing work smart/ live well environment.We genuinely care about the work that we deliver and the people who help make it all possible. We only invest in projects, people and practices that we believe in, to ensure we remain excited about every opportunity.', 'We are negotiable on salary and there is the potential for equity for the right candidate.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [22/Jul/2022 15:13:36] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stylect is a dynamic startup that helps helps women discover and buy shoes. We’re a small team based in London that has previously worked at Google, Techstars, Pixelmator and Rocket Internet.We place a high premium on simplicity no matter what we’re working on (i.e. design, programming, marketing). We’re also a team that ships fast. We built version 1 of our app in a week, the next release (built in a month) was featured in the Apple Appstore Italy as a best new fashion app. Fast release cycles are challenging, but also very fun - which is why we love them. As we’ve grown, the projects that we’re working on have grown both in scale and in technical complexity.  Stylect is looking for someone who can help us improve our backend which gathers product data; analyses/categorizes it; and shows it to thousands of users daily. Each step in the process has unique challenges that demands a strong technical background.\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iNBEG8IAyJ7t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}